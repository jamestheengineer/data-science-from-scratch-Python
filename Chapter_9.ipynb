{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMlX8E7OEPbCg289skKGGwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O_o0ZUx31-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting data\n",
        "\n",
        "# You can pipe data using stdin and stdout\n",
        "\n",
        "# egrep.py\n",
        "import sys, re\n",
        "\n",
        "# sys.argv is the list of command-line arguments\n",
        "# sys.argv[0] is the name of the program itself\n",
        "# sys.argv[1] will be the regex specified at the command line\n",
        "regex = sys.argv[1]\n",
        "\n",
        "# for every line passed into the script\n",
        "for line in sys.stdin:\n",
        "  # if it matches the regex, write it to stdout\n",
        "  if re.search(regex, line):\n",
        "    sys.stdout.write(line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW3_cdc34p2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# line_count.py\n",
        "count = 0\n",
        "for line in sys.stdin:\n",
        "  count += 1\n",
        "\n",
        "# print goes to sys.stdout\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TvNGc1Q4zjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If I were to break these files out, you could then pipe like:\n",
        "# type SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeNjirtQ44b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# another potential script\n",
        "# most_common_words.py\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "# pass in number of words as first argument\n",
        "try:\n",
        "  num_words : int(sys.argv[1])\n",
        "except:\n",
        "  print(\"usage: most_common_words.py num_words\")\n",
        "  sys.exit(1) # nonzero exit code indicates error\n",
        "\n",
        "counter = Counter(word.lower()                      # lowercase words\n",
        "                  for line in sys.stdin\n",
        "                  for word in line.strip().split()  # split on spaces\n",
        "                  if word)                          # skip empty 'words'\n",
        "\n",
        "for word, count in counter.most_common(num_words):\n",
        "  sys.stdout.write(str(count))\n",
        "  sys.stdout.write(\"\\t\")\n",
        "  sys.stdout.write(word)\n",
        "  sys.stdout.write(\"\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm4BuK8W5CB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then you could do\n",
        "# cat the_bible.txt | python most_common_words.py 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVWQKOI5AMHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading Files\n",
        "p = \"\"\"\n",
        "Some random text to write out\n",
        "# lets start some lines like this\n",
        "# and this\n",
        "\"\"\"\n",
        "text_file = open(\"text.txt\", \"w+\");text_file.write(p);text_file.close()\n",
        "\n",
        "# 'r' means read-only, it's assumed if you leave it out\n",
        "file_for_reading = open('text.txt', 'r')\n",
        "file_for_reading2 = open('text.txt')\n",
        "\n",
        "# 'w' if write -- will destroy the file if it already exists!\n",
        "file_for_writing = open('writing_file.txt', 'w')\n",
        "\n",
        "# 'a' is append -- for adding to the end of the file\n",
        "file_for_appending = open('appending_file.txt', 'a')\n",
        "\n",
        "# don't forget to close your files when you are done\n",
        "file_for_writing.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1g1_kN0vqB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python will auto close files if you use a with block\n",
        "# with open('text.txt') as f:\n",
        "#  data = function_that_get_data_from(f)\n",
        "\n",
        "# at this point f has already been closed, so don't try to use it\n",
        "# process(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeaRQCPzxA3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you need to read a whole file, you can iterate over the lines of the file\n",
        "starts_with_hash = 0\n",
        "\n",
        "with open('text.txt') as f:\n",
        "  for line in f:              # look at each line in the file\n",
        "    if re.match(\"^#\", line):  # user a regex to see if it starts with '#'\n",
        "      starts_with_hash += 1   # if it does, add 1 to the count\n",
        "\n",
        "print(starts_with_hash)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt_qqfNsyavA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's get some domain names (although you can trip this particular approach up)\n",
        "def get_domain(email_address: str) -> str:\n",
        "  \"\"\"Split on '@' and return the last piece\"\"\"\n",
        "  return email_address.lower().split(\"@\")[-1]\n",
        "\n",
        "# a couple of tests\n",
        "assert get_domain('joelgrus@gmail.com') == 'gmail.com'\n",
        "assert get_domain('joel@m.datasciencester.com') == 'm.datasciencester.com'\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "#with open('email_addresses.txt', 'r') as f:\n",
        "#  domain_counts = Counter(get_domain(line.strip())\n",
        "#                          for line in f\n",
        "#                          if \"@\" in line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjFqbHji3UeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delimited files are most common. Edge cases are tough when dealing with tabs\n",
        "# or spaces or commas, so you shouldn't try to parse these yourself\n",
        "\n",
        "# Stock prices\n",
        "stock_prices = \"\"\"6/20/2014\\tAA\\t90.91\n",
        "6/20/2014\\tMSFT\\t41.68\n",
        "6/20/2014\\tFB\\t64.50\n",
        "\"\"\"\n",
        "print(stock_prices)\n",
        "\n",
        "text_file = open(\"stock_prices.txt\", \"w+\");text_file.write(stock_prices);text_file.close()\n",
        "\n",
        "import csv\n",
        "\n",
        "with open('stock_prices.txt') as f:\n",
        "  tab_reader = csv.reader(f, delimiter='\\t')\n",
        "  for row in tab_reader:\n",
        "    print(row)\n",
        "    date = row[0]\n",
        "    symbol = row[1]\n",
        "    closing_price = float(row[2])\n",
        "    #process(date, symbol, closing_price)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urrpM2TI8Ibx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can also use a DictReader\n",
        "with open('colon_delimted_stock_prices.txt') as f:\n",
        "  colon_reader = csv.DictReader(f, delimiter = ':')\n",
        "  for dict_row in colon_reader:\n",
        "    date = dict_row[\"date\"]\n",
        "    symbol = dict_row[\"symbol\"]\n",
        "    closing_price = float(dict_row[\"closing_price\"])\n",
        "    process(date, symbol, closing_price)\n",
        "\n",
        "# You can still use DictReader even if your data doesn't have headers by passing it the keys as a 'fieldnames' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nT-NNt6h4z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can write out data using csv.writer\n",
        "todays_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5}\n",
        "\n",
        "with open('comma_delimited_stock_prices.txt', 'w') as f:\n",
        "  csv_writer = csv.writer(f, delimiter = ',')\n",
        "  for stock, price in todays_prices.items():\n",
        "    csv_writer.writerow([stock, price])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P50oI5Uh6SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scraping the web. We'll use a couple external packages (i.e., not from scratch)\n",
        "!pip install beautifulsoup4 requests html5lib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4wNsOUjjHfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = (\"https://raw.githubusercontent.com/\"\n",
        "        \"joelgrus/data/master/getting-data.html\")\n",
        "print(url)\n",
        "html = requests.get(url).text\n",
        "soup = BeautifulSoup(html, 'html5lib')\n",
        "\n",
        "first_paragraph = soup.find('p')\n",
        "first_paragraph_text = soup.p.text\n",
        "first_paragraph_words = soup.p.text.split()\n",
        "print(first_paragraph_text, first_paragraph_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP4FP1AEoWqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can tag attributes by treating soup like a dict\n",
        "first_paragraph_id = soup.p['id']\n",
        "first_paragraph_id2 = soup.p.get('id')\n",
        "print(first_paragraph_id, first_paragraph_id2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qN-Zm84pgzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can multiple tags at once\n",
        "all_paragraphs = soup.find_all('p') # or just soup('p')\n",
        "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7q-zoSWqG3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's how you find classes\n",
        "important_paragraphs = soup('p', {'class' : 'important'})\n",
        "important_paragraphs2 = soup('p', 'important')\n",
        "important_paragraphs3 = [ p for p in soup('p')\n",
        "                          if 'important' in p.get('class', [])]\n",
        "print(important_paragraphs, important_paragraphs2, important_paragraphs3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grDWA-a7qmHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spans in divs. Warning: will return the same <span> multiple times if it sits\n",
        "# inside multiple <div>s. Be more clever if that is the case\n",
        "spans_inside_divs = [span\n",
        "                     for div in soup('div')\n",
        "                     for span in div('span')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTACSBlfrTFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: Keeping tabs on Congress"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}