{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_20.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3s8qiGUV9NLix/NJnUlbn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BA6YCGCN6VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "72d20802-7415-45dc-91b4-8abd1b724cbc"
      },
      "source": [
        "# Clustering chapter. Example of unsupervised learning.\n",
        "\n",
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data-science-from-scratch-Python'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 480 (delta 60), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (480/480), 1.18 MiB | 14.01 MiB/s, done.\n",
            "Resolving deltas: 100% (300/300), done.\n",
            "/content/data-science-from-scratch-Python\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=b785eb1d06d2762e12a3bd03480f6768a2ba359dc1cef515e7321fa2ffe7a8ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXrijZVrO1KG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9651ebd-d593-4948-fe7c-b3e72fe43da6"
      },
      "source": [
        "from Chapter_04 import Vector\n",
        "\n",
        "def num_differences(v1: Vector, v2: Vector) -> int:\n",
        "  assert len(v1) == len(v2)\n",
        "  return len([x1 for x1, x2 in zip(v1,v2) if x1 != x2])\n",
        "\n",
        "assert num_differences([1,2,3],[2,1,3]) == 2\n",
        "assert num_differences([1,2],[1,2]) == 0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from Chapter_04.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBuUadQQPbZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List\n",
        "from Chapter_04 import vector_mean\n",
        "\n",
        "def cluster_means(k: int,\n",
        "                  inputs: List[Vector],\n",
        "                  assignments: List[int]) -> List[Vector]:\n",
        "  # cluster[i] contains the inputs whose assignment is i\n",
        "  clusters = [[] for i in range(k)]\n",
        "  for input, assignment in zip(inputs, assignents):\n",
        "    clusters[assignment].append(input)\n",
        "\n",
        "  # if a cluster is empty, just use a random point\n",
        "  return [vector_mean(cluster) if cluster else random.choice(inputs)\n",
        "          for cluster in clusters]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6gC12KAQT6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "import tqdm\n",
        "from Chapter_04 import squared_distance\n",
        "\n",
        "class KMeans:\n",
        "  def __init__(self, k: int) -> None:\n",
        "    self.k = k\n",
        "    self.means = None\n",
        "\n",
        "  def classify(self, input: Vector) -> int:\n",
        "    \"\"\"return the index of the cluster closes to the input\"\"\"\n",
        "    return min(range(self.k),\n",
        "               key=lambda i: squared_distance(input, self.means[i]))\n",
        "    \n",
        "  def train(self, inputs: List[Vector]) -> None:\n",
        "    # Start with random assignments\n",
        "    assignments = [random.randrange(self.k) for _ in inputs]\n",
        "\n",
        "    with tqdm.tqdm(itertools.count()) as t:\n",
        "      for _ in t:\n",
        "        # Compute means and find new assignments\n",
        "        self.means = cluster_means(self.k, inputs, assignments)\n",
        "        new_assignments = [self.classify(input) for input in inputs]\n",
        "\n",
        "        # Check how many assignments changed and if we're done\n",
        "        num_changed = num_differences(assignments, new_assignments)\n",
        "        if num_changed == 0:\n",
        "          return\n",
        "        \n",
        "        # Otherwise keep the new assignments, and compute new means\n",
        "        assignments = new_assignments\n",
        "        self.means = cluster_means(self.k, inputs, assignments)\n",
        "        t.set_description(f\"changed: {num_changed} / {len(inputs)}\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyy1gLN7CpMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}