{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_20.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQ/ftNASA2698LsoBAz4PS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BA6YCGCN6VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "05714a30-c98c-451d-f7ab-5421b95f0e4e"
      },
      "source": [
        "# Clustering chapter. Example of unsupervised learning.\n",
        "\n",
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "!pip install pillow\n",
        "import import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data-science-from-scratch-Python'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 489 (delta 66), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (489/489), 1.18 MiB | 2.92 MiB/s, done.\n",
            "Resolving deltas: 100% (306/306), done.\n",
            "/content/data-science-from-scratch-Python\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=7ed9f717796cf030fdd655ec1249f6b30856ec684dda250b1520a19554d6eaa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXrijZVrO1KG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Chapter_04 import Vector\n",
        "\n",
        "def num_differences(v1: Vector, v2: Vector) -> int:\n",
        "  assert len(v1) == len(v2)\n",
        "  return len([x1 for x1, x2 in zip(v1,v2) if x1 != x2])\n",
        "\n",
        "assert num_differences([1,2,3],[2,1,3]) == 2\n",
        "assert num_differences([1,2],[1,2]) == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBuUadQQPbZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List\n",
        "from Chapter_04 import vector_mean\n",
        "\n",
        "def cluster_means(k: int,\n",
        "                  inputs: List[Vector],\n",
        "                  assignments: List[int]) -> List[Vector]:\n",
        "  # cluster[i] contains the inputs whose assignment is i\n",
        "  clusters = [[] for i in range(k)]\n",
        "  for input, assignment in zip(inputs, assignments):\n",
        "    clusters[assignment].append(input)\n",
        "\n",
        "  # if a cluster is empty, just use a random point\n",
        "  return [vector_mean(cluster) if cluster else random.choice(inputs)\n",
        "          for cluster in clusters]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6gC12KAQT6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "import tqdm\n",
        "from Chapter_04 import squared_distance\n",
        "\n",
        "class KMeans:\n",
        "  def __init__(self, k: int) -> None:\n",
        "    self.k = k\n",
        "    self.means = None\n",
        "\n",
        "  def classify(self, input: Vector) -> int:\n",
        "    \"\"\"return the index of the cluster closes to the input\"\"\"\n",
        "    return min(range(self.k),\n",
        "               key=lambda i: squared_distance(input, self.means[i]))\n",
        "    \n",
        "  def train(self, inputs: List[Vector]) -> None:\n",
        "    # Start with random assignments\n",
        "    assignments = [random.randrange(self.k) for _ in inputs]\n",
        "\n",
        "    with tqdm.tqdm(itertools.count()) as t:\n",
        "      for _ in t:\n",
        "        # Compute means and find new assignments\n",
        "        self.means = cluster_means(self.k, inputs, assignments)\n",
        "        new_assignments = [self.classify(input) for input in inputs]\n",
        "\n",
        "        # Check how many assignments changed and if we're done\n",
        "        num_changed = num_differences(assignments, new_assignments)\n",
        "        if num_changed == 0:\n",
        "          return\n",
        "        \n",
        "        # Otherwise keep the new assignments, and compute new means\n",
        "        assignments = new_assignments\n",
        "        self.means = cluster_means(self.k, inputs, assignments)\n",
        "        t.set_description(f\"changed: {num_changed} / {len(inputs)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyy1gLN7CpMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Meetup location example\n",
        "inputs: List[List[float]] = [[-14,-5],[13,13],[20,23],[-19,-11],[-9,-16],[21,27],[-49,15],[26,13],[-46,5],[-34,-1],[11,15],[-49,0],[-22,-16],[19,28],[-12,-8],[-13,-19],[-41,8],[-11,-6],[-25,-9],[-18,-3]]\n",
        "\n",
        "random.seed(12)\n",
        "clusterer = KMeans(k=3)\n",
        "clusterer.train(inputs)\n",
        "means = sorted(clusterer.means)\n",
        "\n",
        "assert len(means) == 3\n",
        "\n",
        "# Check that the means are close to what we expect\n",
        "assert squared_distance(means[0], [-44, 5]) < 1\n",
        "assert squared_distance(means[1], [-16, -10]) < 1\n",
        "assert squared_distance(means[2], [18, 20]) < 1 \n",
        "print(means)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mRzeEL8igU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only cash for two meetups, so...\n",
        "random.seed(0)\n",
        "clusterer = KMeans(k=2)\n",
        "clusterer.train(inputs)\n",
        "means = sorted(clusterer.means)\n",
        "\n",
        "assert len(means) == 2\n",
        "assert squared_distance(means[0], [-26, -5]) < 1\n",
        "assert squared_distance(means[1], [18, 20]) < 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lb50BB3jRtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choosing k by looking at the \"bend\"\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "def squared_clustering_errors(inputs: List[Vector], k: int) -> float:\n",
        "  \"\"\"finds the total squared error from k-means clustering the inputs\"\"\"\n",
        "  clusterer = KMeans(k)\n",
        "  clusterer.train(inputs)\n",
        "  means = clusterer.means\n",
        "  assignments = [clusterer.classify(input) for input in inputs]\n",
        "\n",
        "  return sum(squared_distance(input, means[cluster])\n",
        "              for input, cluster in zip(inputs, assignments))\n",
        "\n",
        "# now plot from 1 up to len(inputs) clusters\n",
        "\n",
        "ks = range(1, len(inputs) + 1)\n",
        "errors = [squared_clustering_errors(inputs, k) for k in ks]\n",
        "\n",
        "plt.plot(ks, errors)\n",
        "plt.xticks(ks)\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"total squared error\")\n",
        "plt.title(\"Total Error vs. # of Clusters\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GezyXXlVnmha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}