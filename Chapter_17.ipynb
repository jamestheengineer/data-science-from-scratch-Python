{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVMrWdxmp+WBenCRTruAN7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXIJahnuYWRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List\n",
        "import math\n",
        "\n",
        "def entropy(class_probabilities: List[float]) -> float:\n",
        "  \"\"\"Given a list of class probabilities, compute the entropy\"\"\"\n",
        "  return sum(-p * math.log(p,2)\n",
        "              for p in class_probabilities\n",
        "             if p > 0) # ignore zero probabilities\n",
        "\n",
        "assert entropy([1.0]) == 0\n",
        "assert entropy([0.5, 0.5]) == 1\n",
        "assert 0.81 < entropy([0.25, 0.75]) < 0.82\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu7UOdk7Zo9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Any\n",
        "from collections import Counter\n",
        "\n",
        "def class_probabilities(labels: List[Any]) -> List[float]:\n",
        "  total_count = len(labels)\n",
        "  return [count / total_count\n",
        "          for count in Counter(labels).values()]\n",
        "\n",
        "def data_entropy(labels: List[Any]) -> float:\n",
        "  return entropy(class_probabilities(labels))\n",
        "\n",
        "assert data_entropy(['a']) == 0\n",
        "assert data_entropy([True, False]) == 1\n",
        "assert data_entropy([3, 4, 4, 4]) == entropy([0.25, 0.75])\n",
        "\n",
        "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
        "  \"\"\"Returns the entropy form this partition of data into subsets\"\"\"\n",
        "  total_count = sum(len(subset) for subset in subsets)\n",
        "\n",
        "  return sum(data_entropy(subset) * len(subset) / total_count\n",
        "             for subset in subsets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkNIQ-UJebKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import NamedTuple, Optional\n",
        "\n",
        "class Candidate(NamedTuple):\n",
        "  level: str\n",
        "  lang: str\n",
        "  tweets: bool\n",
        "  phd: bool\n",
        "  did_well: Optional[bool] = None # allow unlabeled data\n",
        "\n",
        "           #  level     lang     tweets  phd  did_well\n",
        "inputs = [Candidate('Senior', 'Java',   False, False, False),\n",
        "          Candidate('Senior', 'Java',   False, True,  False),\n",
        "          Candidate('Mid',    'Python', False, False, True),\n",
        "          Candidate('Junior', 'Python', False, False, True),\n",
        "          Candidate('Junior', 'R',      True,  False, True),\n",
        "          Candidate('Junior', 'R',      True,  True,  False),\n",
        "          Candidate('Mid',    'R',      True,  True,  True),\n",
        "          Candidate('Senior', 'Python', False, False, False),\n",
        "          Candidate('Senior', 'R',      True,  False, True),\n",
        "          Candidate('Junior', 'Python', True,  False, True),\n",
        "          Candidate('Senior', 'Python', True,  True,  True),\n",
        "          Candidate('Mid',    'Python', False, True,  True),\n",
        "          Candidate('Mid',    'Java',   True,  False, True),\n",
        "          Candidate('Junior', 'Python', False, True,  False)\n",
        "         ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYsKvqr4ysVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Dict, TypeVar\n",
        "from collections import defaultdict\n",
        "\n",
        "T = TypeVar('T') # generic type for inputs\n",
        "\n",
        "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
        "  \"\"\"Partition the inputs into lists based on the specified attribute.\"\"\"\n",
        "  partitions: Dict[Any, List[T]] = defaultdict(list)\n",
        "  for input in inputs:\n",
        "    key = getattr(input, attribute) # value of the specified attribute\n",
        "    partitions[key].append(input) # add input to the correct partition\n",
        "  return partitions\n",
        "\n",
        "def partition_entropy_by(inputs: List[Any],\n",
        "                         attribute: str,\n",
        "                         label_attribute: str) -> float:\n",
        "  \"\"\"Compute the entropy correspionding to the given partition\"\"\"\n",
        "  # partitions consist of our inputs\n",
        "  partitions = partition_by(inputs, attribute)\n",
        "\n",
        "  # but partition_entropy needs just the class labels\n",
        "  labels = [[getattr(input, label_attribute) for input in partition]\n",
        "            for partition in partitions.values()]\n",
        "  \n",
        "  return partition_entropy(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjXXWBO0Ich5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "14f67bb1-59d2-420d-f266-ff7aaf5daba6"
      },
      "source": [
        "for key in ['level', 'lang', 'tweets', 'phd']:\n",
        "  print(key, partition_entropy_by(inputs, key, 'did_well'))\n",
        "\n",
        "assert 0.69 < partition_entropy_by(inputs, 'level', 'did_well') < 0.70\n",
        "assert 0.86 < partition_entropy_by(inputs, 'lang', 'did_well') < 0.87\n",
        "assert 0.78 < partition_entropy_by(inputs, 'tweets', 'did_well') < 0.79\n",
        "assert 0.89 < partition_entropy_by(inputs, 'phd', 'did_well') < 0.90"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level 0.6935361388961919\n",
            "lang 0.8601317128547441\n",
            "tweets 0.7884504573082896\n",
            "phd 0.8921589282623617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dxwQY58KkM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "senior_inputs = [input for input in inputs if input.level == 'Senior']\n",
        "\n",
        "assert 0.4 == partition_entropy_by(senior_inputs, 'lang', 'did_well')\n",
        "assert 0.0 == partition_entropy_by(senior_inputs, 'tweets', 'did_well')\n",
        "assert 0.95 < partition_entropy_by(senior_inputs, 'phd', 'did_well')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NHnrkTMKzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import NamedTuple, Union, Any\n",
        "\n",
        "class Leaf(NamedTuple):\n",
        "  value: Any\n",
        "\n",
        "class Split(NamedTuple):\n",
        "  attribute: str\n",
        "  subtrees: dict\n",
        "  default_value: Any = None\n",
        "\n",
        "DecisionTree = Union[Leaf, Split]\n",
        "hiring_tree = Split('level', {  # first, consider \"level\"\n",
        "    'Junior': Split('phd', {    # if level is Junior, next look at phd\n",
        "        False: Leaf(True),      # if phd is false, predict true\n",
        "        True: Leaf(False)       # if phd is true, predict false\n",
        "    }),\n",
        "    'Mid': Leaf(True),           # if level is mid, just predict true\n",
        "    'Senior': Split('tweets', {  # if level is sewnior, look at tweets\n",
        "        False: Leaf(False),       # if tweets is false, predict false\n",
        "        True: Leaf(True)\n",
        "  })\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP_a6NTnw1LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(tree: DecisionTree, input: Any) -> Any:\n",
        "  \"\"\"Classify the input using the given decision tree\"\"\"\n",
        "  # If this is a leaf node, return its value\n",
        "  if isinstance(tree, Leaf):\n",
        "    return tree.value\n",
        "\n",
        "  # Otherwise this tree consists of an attribute to split on\n",
        "  # and a dictionary whose keys are values of that attribute\n",
        "  # and whose values are subtrees to consider next\n",
        "  subtree_key = getattr(input, tree.attribute)\n",
        "\n",
        "  if subtree_key not in tree.subtrees:  # If no subtree for key,\n",
        "    return tree.default_value           # return the default value\n",
        "\n",
        "  subtree = tree.subtrees[subtree_key]  # Choose the appropriate subtree\n",
        "  return classify(subtree, input)       # and use it to classify the input.\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEcVp66RCsof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_tree_id3(inputs: List[Any],\n",
        "                   split_attributes: List[str],\n",
        "                   target_attribute: str) -> DecisionTree:\n",
        "    # Count target labels\n",
        "    label_counts = Counter(getattr(input, target_attribute)\n",
        "                            for input in inputs)\n",
        "    most_common_label = label_counts.most_common(1)[0][0]\n",
        "\n",
        "    # If there's a unique label, predict it\n",
        "    if len(label_counts) == 1:\n",
        "      return Leaf(most_common_label)\n",
        "\n",
        "    # If no split attributes left, return the majority label\n",
        "    if not split_attributes:\n",
        "      return Leaf(most_common_labels)\n",
        "\n",
        "# Otherwise split by the best attribute\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}