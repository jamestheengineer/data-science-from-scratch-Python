{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfD8/uhxGdXUAIhMSQcZt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz0lIKWRds6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf0DS1yLbujQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k-Nearest Neighbors\n",
        "from typing import List\n",
        "from collections import Counter\n",
        "\n",
        "def raw_majority_vote(labels: List[str]) -> str:\n",
        "  votes= Counter(labels)\n",
        "  winner, _ = votes.most_common(1)[0]\n",
        "  return winner\n",
        "\n",
        "assert raw_majority_vote(['a','b','c','b']) == 'b'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26dBmducknw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The previous function doesn't handle ties. Let's reduce k until we find a unique winner\n",
        "def majority_vote(labels: List[str]) -> str:\n",
        "  \"\"\"Assumes that labels are ordered from nearest to farthest.\"\"\"\n",
        "  vote_counts = Counter(labels)\n",
        "  winner, winner_count = vote_counts.most_common(1)[0]\n",
        "  num_winners = len([count\n",
        "                     for count in vote_counts.values()\n",
        "                     if count == winner_count])\n",
        "  if num_winners == 1:\n",
        "    return winner\n",
        "  else:\n",
        "    return majority_vote(labels[:-1]) # try again without the farthest\n",
        "\n",
        "# Tie, so look at first 4\n",
        "assert majority_vote(['a','b','c','b','a']) == 'b'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myovvi54eBpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import NamedTuple\n",
        "import import_ipynb\n",
        "from Chapter_4 import Vector, distance\n",
        "\n",
        "class LabeledPoint(NamedTuple):\n",
        "  point: Vector\n",
        "  label: str\n",
        "\n",
        "def knn_classify(k: int,\n",
        "                 labeled_points: List[LabeledPoint],\n",
        "                 new_point: Vector) -> str:\n",
        "    # Order the labeled points from nearest to farthest\n",
        "    by_distance = sorted(labeled_points,\n",
        "                         key=lambda lp: distance(lp.point, new_point))\n",
        "    \n",
        "    # Find the labels for the k closest\n",
        "    k_nearest_labels = [lp.label for lp in by_distance[:k]]\n",
        "\n",
        "    # And let them vote\n",
        "    return majority_vote(k_nearest_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQiC0IYc1Ro9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's do an example\n",
        "import requests\n",
        "\n",
        "data = requests.get(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        ")\n",
        "\n",
        "with open('iris.dat', 'w') as f:\n",
        "  f.write(data.text)\n",
        "\n",
        "print(data.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt7R_TbKgeAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from typing import Dict\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "def parse_iris_row(row: List[str]) -> LabeledPoint:\n",
        "  \"\"\"\n",
        "  sepal_length, sepal_width, petal_length, petal_width, class\n",
        "  \"\"\"\n",
        "  measurements = [float(value) for value in row[:-1]]\n",
        "  # Class is e.g., \"Iris-virginica\"; we just want \"virginica\"\n",
        "  label = row[-1].split(\"-\")[-1]\n",
        "\n",
        "  return LabeledPoint(measurements, label)\n",
        "\n",
        "with open('iris.dat') as f:\n",
        "  reader = csv.reader(f)\n",
        "  print(row_count)\n",
        "  iris_data = [parse_iris_row(row) for row in reader if any(row)]\n",
        "  print(len(iris_data))\n",
        " \n",
        "# We'll also group just the points by species/label so we can plot them\n",
        "points_by_species: Dict[str, List[Vector]] = defaultdict(list)\n",
        "for iris in iris_data:\n",
        "  points_by_species[iris.label].append(iris.point)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjB94R5N3Xfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's plot\n",
        "from matplotlib import pyplot as plt\n",
        "metrics = ['sepal length', 'sepal width','petal length','petal width']\n",
        "pairs = [(i,j) for i in range(4) for j in range(4) if i < j]\n",
        "print(pairs)\n",
        "marks = ['+','.','x'] # we have 3 classes, so 3 markers\n",
        "\n",
        "fig, ax = plt.subplots(2,3)\n",
        "\n",
        "for row in range(2):\n",
        "  for col in range(3):\n",
        "    i, j = pairs[3 * row + col]\n",
        "    ax[row][col].set_title(f\"{metrics[i]} vs {metrics[j]}\", fontsize=8)\n",
        "    ax[row][col].set_xticks([])\n",
        "    ax[row][col].set_yticks([])\n",
        "    \n",
        "    for mark, (species, points) in zip(marks, points_by_species.items()):\n",
        "        xs = [point[i] for point in points]\n",
        "        ys = [point[j] for point in points]\n",
        "        ax[row][col].scatter(xs, ys, marker=mark, label=species)\n",
        "    \n",
        "ax[-1][-1].legend(loc='lower right', prop={'size': 6})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY8JWDuR9TcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plots make it seem like we should be able to kNN this, so let's do it\n",
        "import random\n",
        "from Chapter_11 import split_data\n",
        "\n",
        "random.seed(12)\n",
        "iris_train, iris_test = split_data(iris_data, 0.70)\n",
        "assert len(iris_train) == 0.7 * 150\n",
        "assert len(iris_test) == 0.3 * 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GfnqXjjBWU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "# track how many times we see (predicted, actual)\n",
        "confusion_matrix: Dict[Tuple[str, str], int] = defaultdict(int)\n",
        "num_correct = 0\n",
        "\n",
        "for iris in iris_test:\n",
        "  predicted = knn_classify(5, iris_train, iris.point)\n",
        "  actual = iris.label\n",
        "\n",
        "  if predicted == actual:\n",
        "    num_correct += 1\n",
        "\n",
        "  confusion_matrix[(predicted, actual)] += 1\n",
        "\n",
        "pct_correct = num_correct / len(iris_test)\n",
        "print(pct_correct, confusion_matrix) # Only misses 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gsok3-aCP5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}