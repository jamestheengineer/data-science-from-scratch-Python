{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_18.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdFtureR4MLxVK4L+qgD7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alazT68gQvSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "a50784e5-56d5-424c-8b84-d2272c476ed6"
      },
      "source": [
        "# Neural Networks\n",
        "\n",
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data-science-from-scratch-Python'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Total 387 (delta 0), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (387/387), 1.05 MiB | 7.29 MiB/s, done.\n",
            "Resolving deltas: 100% (240/240), done.\n",
            "/content/data-science-from-scratch-Python\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=97b229ee7fee3709ded699570666acea9effca58d4a82ef8f6bf53889ec8e4b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5cmZsztRQ1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4658ccc3-243b-4845-c731-9d7119307e03"
      },
      "source": [
        "from Chapter_04 import Vector, dot\n",
        "\n",
        "def step_function(x: float) -> float:\n",
        "  return 1.0 if x >= 0 else 0.0\n",
        "\n",
        "def perceptron_output(weights: Vector, bias: float, x: Vector) -> float:\n",
        "  \"\"\"Returns 1 if the perceptron 'fires', 0 if not\"\"\"\n",
        "  calculation = dot(weights, x) + bias\n",
        "  return step_function(calculation)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from Chapter_04.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvrpxOvdR_vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AND Gate\n",
        "and_weights = [2., 2]\n",
        "and_bias = -3.\n",
        "\n",
        "assert perceptron_output(and_weights, and_bias, [1,1]) == 1\n",
        "assert perceptron_output(and_weights, and_bias, [0,1]) == 0\n",
        "assert perceptron_output(and_weights, and_bias, [1,0]) == 0\n",
        "assert perceptron_output(and_weights, and_bias, [0,0]) == 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewYxTjeqfxhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OR Gate\n",
        "or_weights = [2., 2]\n",
        "or_bias = -1.\n",
        "\n",
        "assert perceptron_output(or_weights, or_bias, [1,1]) == 1\n",
        "assert perceptron_output(or_weights, or_bias, [1,0]) == 1\n",
        "assert perceptron_output(or_weights, or_bias, [0,1]) == 1\n",
        "assert perceptron_output(or_weights, or_bias, [0,0]) == 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9_hjkT6gdE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOT Gate\n",
        "not_weights = [-2.]\n",
        "not_bias = 1.\n",
        "\n",
        "assert perceptron_output(not_weights, not_bias, [0]) == 1\n",
        "assert perceptron_output(not_weights, not_bias, [1]) == 0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9ToIp5nhHo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XOR gate\n",
        "and_gate = min\n",
        "or_gate = max\n",
        "xor_gate = lambda x, y: 0 if x== y else 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PmNidyThXxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}