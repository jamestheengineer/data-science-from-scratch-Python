{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+ciz+q3XFHPhdTbusB1Ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWpFltnXEArw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Bayes for spam filter\n",
        "from typing import Set\n",
        "import re\n",
        "\n",
        "def tokenize(text: str) -> Set[str]:\n",
        "  text = text.lower()\n",
        "  all_words = re.findall(\"[a-z0-9']+\", text) # extract the words\n",
        "  return set(all_words) # and remove duplicates\n",
        "\n",
        "assert tokenize(\"Data Science is science\") == {\"data\", \"science\", \"is\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn9iGZ9DE_3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "class Message(NamedTuple):\n",
        "  text: str\n",
        "  is_spam: bool\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8gGgMzrFMAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Tuple, Dict, Iterable\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, k: float = 0.5) -> None:\n",
        "    self.k = k # smoothing factor\n",
        "    self.tokens: Set[str] = set()\n",
        "    self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
        "    self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
        "    self.spam_messages = self.ham_messages = 0\n",
        "  \n",
        "  def train(self, messages: Iterable[Message]) -> None:\n",
        "    for message in messages:\n",
        "      # Increment message counts\n",
        "      if message.is_spam:\n",
        "        self.spam_messages += 1\n",
        "      else:\n",
        "        self.ham_messages += 1\n",
        "\n",
        "      # Increment word counts\n",
        "      for token in tokenize(message.text):\n",
        "        self.tokens.add(token)\n",
        "        if message.is_spam:\n",
        "          self.token_spam_counts[token] += 1\n",
        "        else:\n",
        "          self.token_ham_counts[token] += 1\n",
        "  \n",
        "  def _probabilities(self, token: str) -> Tuple[float, float]:\n",
        "    \"\"\"returns P(token | spam) and P(token | ham)\"\"\"\n",
        "    spam = self.token_spam_counts[token]\n",
        "    ham = self.token_ham_counts[token]\n",
        "\n",
        "    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
        "    p_token_ham = (ham + self.k) / (self.ham_messages) + 2 * self.k)\n",
        "\n",
        "    return p_token_spam, p_token_ham\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADvMl2ZgF4-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}