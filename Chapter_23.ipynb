{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_23.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3W+Auv1SrKz3S1mpaQe9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BIMq_aHMWZV",
        "outputId": "6bb13fe4-6f46-4f24-f879-12adb20522c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data-science-from-scratch-Python'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 624 (delta 10), reused 0 (delta 0), pack-reused 606\u001b[K\n",
            "Receiving objects: 100% (624/624), 1.64 MiB | 10.80 MiB/s, done.\n",
            "Resolving deltas: 100% (391/391), done.\n",
            "/content/data-science-from-scratch-Python\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=98c4fb23e9c38c16ddfd04cffc075a502fabf1e46e5afee51a31b102a32727f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKitV8nxGD3B"
      },
      "source": [
        "users_interests = [\n",
        "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
        "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
        "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
        "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
        "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
        "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
        "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
        "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
        "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
        "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
        "    [\"statistics\", \"R\", \"statsmodels\"],\n",
        "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
        "    [\"pandas\", \"R\", \"Python\"],\n",
        "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
        "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGmOBhEBGKGv",
        "outputId": "239366f6-66e5-472c-a4ac-ae970ad1634c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# One simple approach is to recommend what is popular\n",
        "from collections import Counter\n",
        "\n",
        "popular_interests = Counter(interest \n",
        "                            for user_interests in users_interests\n",
        "                            for interest in user_interests)\n",
        "print(popular_interests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'Python': 4, 'R': 4, 'Big Data': 3, 'HBase': 3, 'Java': 3, 'statistics': 3, 'regression': 3, 'probability': 3, 'Hadoop': 2, 'Cassandra': 2, 'MongoDB': 2, 'Postgres': 2, 'scikit-learn': 2, 'statsmodels': 2, 'pandas': 2, 'machine learning': 2, 'libsvm': 2, 'C++': 2, 'neural networks': 2, 'deep learning': 2, 'artificial intelligence': 2, 'Spark': 1, 'Storm': 1, 'NoSQL': 1, 'scipy': 1, 'numpy': 1, 'decision trees': 1, 'Haskell': 1, 'programming languages': 1, 'mathematics': 1, 'theory': 1, 'Mahout': 1, 'MapReduce': 1, 'databases': 1, 'MySQL': 1, 'support vector machines': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQzJeflYGsfo",
        "outputId": "25e1851f-6300-4051-d2b5-5ad32b647780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# We can the just suggest the most popular itnerests that are not already in a user's list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def most_popular_new_interests(\n",
        "        user_interests : List[str],\n",
        "        max_results: int = 5) -> List[Tuple[str, int]]:\n",
        "    suggestions = [(interest, frequency)\n",
        "                    for interest, frequency in popular_interests.most_common()\n",
        "                    if interest not in user_interests]\n",
        "    return suggestions[:max_results]\n",
        "\n",
        "print(most_popular_new_interests(users_interests[1]))\n",
        "print(most_popular_new_interests(users_interests[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Python', 4), ('R', 4), ('Big Data', 3), ('Java', 3), ('statistics', 3)]\n",
            "[('Python', 4), ('R', 4), ('statistics', 3), ('regression', 3), ('probability', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlysjJvoIXQL",
        "outputId": "b04380dc-24cc-48ee-a419-aea1da3e8eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Collaborative filtering to find new interests based on similarity to others who have similar things to you\n",
        "unique_interests = sorted({interest\n",
        "                           for user_interests in users_interests\n",
        "                           for interest in user_interests})\n",
        "assert unique_interests[:6] == [\n",
        "                                'Big Data',\n",
        "                                'C++',\n",
        "                                'Cassandra',\n",
        "                                'HBase',\n",
        "                                'Hadoop',\n",
        "                                'Haskell',\n",
        "]\n",
        "print(unique_interests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Big Data', 'C++', 'Cassandra', 'HBase', 'Hadoop', 'Haskell', 'Java', 'Mahout', 'MapReduce', 'MongoDB', 'MySQL', 'NoSQL', 'Postgres', 'Python', 'R', 'Spark', 'Storm', 'artificial intelligence', 'databases', 'decision trees', 'deep learning', 'libsvm', 'machine learning', 'mathematics', 'neural networks', 'numpy', 'pandas', 'probability', 'programming languages', 'regression', 'scikit-learn', 'scipy', 'statistics', 'statsmodels', 'support vector machines', 'theory']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnQKxr-3K2Gq",
        "outputId": "19585f24-0f86-4cec-b2aa-532f9ee97738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Next we produce an interest vector of 0s and 10s for each user\n",
        "def make_user_interest_vector(user_interests: List[str]) -> List[int]:\n",
        "  \"\"\"\n",
        "  Given a list of interests, produce a vector whose ith element is 1\n",
        "  if unique_interests[i] is in the list, 0 otherwise\n",
        "  \"\"\"\n",
        "  return [1 if interest in user_interests else 0\n",
        "          for interest in unique_interests]\n",
        "\n",
        "user_interest_vectors = [make_user_interest_vector(user_interests)\n",
        "                        for user_interests in users_interests]\n",
        "print(user_interest_vectors)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYSBpdML2Dn"
      },
      "source": [
        "# Because we have a small dataset, it's no problem to compute the pairwise similarities\n",
        "from Chapter_21 import cosine_similarity\n",
        "\n",
        "user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)\n",
        "                      for interest_vector_j in user_interest_vectors]\n",
        "                     for interest_vector_i in user_interest_vectors]\n",
        "\n",
        "assert 0.56 < user_similarities[0][9] < 0.58, \"several shared interests\"\n",
        "assert 0.18 < user_similarities[0][8] < 0.20, \"only one shared interest\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnq-blCkQQ-w",
        "outputId": "73c2215e-e212-4aaf-b0d4-69b5506df82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def most_similar_users_to(user_id: int) -> List[Tuple[int, float]]:\n",
        "  pairs = [(other_user_id, similarity) \n",
        "            for other_user_id, similarity in\n",
        "                enumerate(user_similarities[user_id])\n",
        "            if user_id != other_user_id and similarity > 0]\n",
        "  return sorted(pairs,\n",
        "                key = lambda pair: pair[-1],\n",
        "                reverse=True)\n",
        "  \n",
        "most_similar_users_to(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(9, 0.5669467095138409),\n",
              " (1, 0.3380617018914066),\n",
              " (8, 0.1889822365046136),\n",
              " (13, 0.1690308509457033),\n",
              " (5, 0.1543033499620919)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRS0KqPzGdg4",
        "outputId": "80ce22b8-71ac-4fda-8d98-c4d10b831cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def user_based_suggestions(user_id: int,\n",
        "                           include_current_interests: bool = False):\n",
        "  # Sum up the similarities\n",
        "  suggestions: Dict[str, float] = defaultdict(float)\n",
        "  for other_user_id, similarity in most_similar_users_to(user_id):\n",
        "    for interest in users_interests[other_user_id]:\n",
        "      suggestions[interest] += similarity\n",
        "\n",
        "  # Convert them to a sorted list\n",
        "  suggestions = sorted(suggestions.items(),\n",
        "                       key=lambda pair: pair[-1], \n",
        "                       reverse=True)\n",
        "  # And (maybe) exclude already interests\n",
        "  if include_current_interests:\n",
        "    return suggestions\n",
        "  else:\n",
        "    return [(suggestion, weight)\n",
        "            for suggestion, weight in suggestions\n",
        "            if suggestion not in users_interests[user_id]]\n",
        "\n",
        "user_based_suggestions(0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('MapReduce', 0.5669467095138409),\n",
              " ('MongoDB', 0.50709255283711),\n",
              " ('Postgres', 0.50709255283711),\n",
              " ('NoSQL', 0.3380617018914066),\n",
              " ('neural networks', 0.1889822365046136),\n",
              " ('deep learning', 0.1889822365046136),\n",
              " ('artificial intelligence', 0.1889822365046136),\n",
              " ('databases', 0.1690308509457033),\n",
              " ('MySQL', 0.1690308509457033),\n",
              " ('Python', 0.1543033499620919),\n",
              " ('R', 0.1543033499620919),\n",
              " ('C++', 0.1543033499620919),\n",
              " ('Haskell', 0.1543033499620919),\n",
              " ('programming languages', 0.1543033499620919)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDVqdzpSIatv"
      },
      "source": [
        "# Item-based suggestions\n",
        "\n",
        "interest_user_matrix = [[user_interest_vector[j]\n",
        "                         for user_interest_vector in user_interest_vectors]\n",
        "                        for j, _ in enumerate(unique_interests)]\n",
        "\n",
        "interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j)\n",
        "                            for user_vector_j in interest_user_matrix]\n",
        "                         for user_vector_i in interest_user_matrix]\n",
        "\n",
        "def most_similar_interests_to(interest_id: int):\n",
        "  similarities = interest_similarities[interest_id]\n",
        "  pairs = [(unique_interests[other_interest_id], similarity)\n",
        "            for other_interest_id, similarity in enumerate(similarities)\n",
        "            if interest_id != other_interest_id and similarity > 0]\n",
        "\n",
        "  return sorted(pairs,\n",
        "                key=lambda pair: pair[-1],\n",
        "                reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHlsuLiLO8q2",
        "outputId": "f8a44f81-24b9-4052-d295-1b6e87e37cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "most_similar_interests_to(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hadoop', 0.8164965809277261),\n",
              " ('Java', 0.6666666666666666),\n",
              " ('MapReduce', 0.5773502691896258),\n",
              " ('Spark', 0.5773502691896258),\n",
              " ('Storm', 0.5773502691896258),\n",
              " ('Cassandra', 0.4082482904638631),\n",
              " ('artificial intelligence', 0.4082482904638631),\n",
              " ('deep learning', 0.4082482904638631),\n",
              " ('neural networks', 0.4082482904638631),\n",
              " ('HBase', 0.3333333333333333)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weW4dvkeQD-f",
        "outputId": "d28cef7f-4b3c-4e8c-abd2-6ff3b3baca5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "def item_based_suggestions(user_id: int,\n",
        "                           include_current_interests: bool = False):\n",
        "  # Add up the similar interests\n",
        "  suggestions = defaultdict(float)\n",
        "  user_interest_vector = user_interest_vectors[user_id]\n",
        "  for interest_id, is_interested in enumerate(user_interest_vector):\n",
        "    if is_interested == 1:\n",
        "      similar_interests = most_similar_interests_to(interest_id)\n",
        "      for interest, similarity in similar_interests:\n",
        "        suggestions[interest] += similarity\n",
        "\n",
        "  # Sort them by weight\n",
        "  suggestions = sorted(suggestions.items(),\n",
        "                       key=lambda pair: pair[-1],\n",
        "                       reverse=True)\n",
        "  \n",
        "  if include_current_interests:\n",
        "    return suggestions\n",
        "  else:\n",
        "    return [(suggestion, weight)\n",
        "            for suggestion, weight in suggestions\n",
        "            if suggestion not in users_interests[user_id]]\n",
        "\n",
        "item_based_suggestions(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('MapReduce', 1.861807319565799),\n",
              " ('MongoDB', 1.3164965809277263),\n",
              " ('Postgres', 1.3164965809277263),\n",
              " ('NoSQL', 1.2844570503761732),\n",
              " ('MySQL', 0.5773502691896258),\n",
              " ('databases', 0.5773502691896258),\n",
              " ('Haskell', 0.5773502691896258),\n",
              " ('programming languages', 0.5773502691896258),\n",
              " ('artificial intelligence', 0.4082482904638631),\n",
              " ('deep learning', 0.4082482904638631),\n",
              " ('neural networks', 0.4082482904638631),\n",
              " ('C++', 0.4082482904638631),\n",
              " ('Python', 0.2886751345948129),\n",
              " ('R', 0.2886751345948129)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2gsVI0VUwjm",
        "outputId": "61920a8e-89a9-4ce6-8911-2e9d00883019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-23 00:20:40--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  26.5MB/s    in 0.2s    \n",
            "\n",
            "2020-10-23 00:20:41 (26.5 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Q6g9l_v_Gr",
        "outputId": "b95e0ec1-af84-4c4f-c8d8-462021108f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!unzip ml-100k.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EabxJPiBwUGe"
      },
      "source": [
        "# This points to the current directory, modify if your files are elsewhere\n",
        "MOVIES = \"ml-100k/u.item\"\n",
        "RATINGS = \"ml-100k/u.data\"\n",
        "from typing import NamedTuple\n",
        "\n",
        "class Rating(NamedTuple):\n",
        "  user_id: str\n",
        "  movie_id: str\n",
        "  rating: float\n",
        "\n",
        "import csv\n",
        "# We specify this encoding to avoid a UnicodeDecodeError\n",
        "# See https://stackoverlow.com/a/53136168/1076346\n",
        "with open(MOVIES, encoding=\"iso-8859-1\") as f:\n",
        "  reader = csv.reader(f, delimiter=\"|\")\n",
        "  movies = {movie_id: title for movie_id, title, *_ in reader}\n",
        "\n",
        "# Create a list of [Rating]\n",
        "with open(RATINGS, encoding=\"iso-8859-1\") as f:\n",
        "  reader = csv.reader(f, delimiter=\"\\t\")\n",
        "  ratings = [Rating(user_id, movie_id, float(rating))\n",
        "              for user_id, movie_id, rating, _ in reader]\n",
        "\n",
        "assert len(movies) == 1682\n",
        "assert len(list({rating.user_id for rating in ratings})) == 943"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceprF2mTwtCE"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}