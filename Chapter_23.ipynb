{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_23.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfFZcT013UECxSiSR4l/Ys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BIMq_aHMWZV",
        "outputId": "05de92d8-dbc6-4a94-dc09-2d4ebe812c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Only do this once per VM, otherwise you'll get multiple clones and nested directories\n",
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data-science-from-scratch-Python'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 609 (delta 0), reused 0 (delta 0), pack-reused 606\u001b[K\n",
            "Receiving objects: 100% (609/609), 1.63 MiB | 17.56 MiB/s, done.\n",
            "Resolving deltas: 100% (381/381), done.\n",
            "/content/data-science-from-scratch-Python\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=f9e6e57f391885a0f422dede87b01b7aa3ff16e59570aea33bfe2112b6f21a2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKitV8nxGD3B"
      },
      "source": [
        "users_interests = [\n",
        "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
        "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
        "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
        "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
        "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
        "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
        "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
        "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
        "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
        "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
        "    [\"statistics\", \"R\", \"statsmodels\"],\n",
        "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
        "    [\"pandas\", \"R\", \"Python\"],\n",
        "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
        "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
        "]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGmOBhEBGKGv",
        "outputId": "4b82e4fa-4865-4b44-872d-43f8c711ab72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# One simple approach is to recommend what is popular\n",
        "from collections import Counter\n",
        "\n",
        "popular_interests = Counter(interest \n",
        "                            for user_interests in users_interests\n",
        "                            for interest in user_interests)\n",
        "print(popular_interests)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'Python': 4, 'R': 4, 'Big Data': 3, 'HBase': 3, 'Java': 3, 'statistics': 3, 'regression': 3, 'probability': 3, 'Hadoop': 2, 'Cassandra': 2, 'MongoDB': 2, 'Postgres': 2, 'scikit-learn': 2, 'statsmodels': 2, 'pandas': 2, 'machine learning': 2, 'libsvm': 2, 'C++': 2, 'neural networks': 2, 'deep learning': 2, 'artificial intelligence': 2, 'Spark': 1, 'Storm': 1, 'NoSQL': 1, 'scipy': 1, 'numpy': 1, 'decision trees': 1, 'Haskell': 1, 'programming languages': 1, 'mathematics': 1, 'theory': 1, 'Mahout': 1, 'MapReduce': 1, 'databases': 1, 'MySQL': 1, 'support vector machines': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQzJeflYGsfo",
        "outputId": "cf091c80-1541-4024-ba58-1d2cb35a96f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# We can the just suggest the most popular itnerests that are not already in a user's list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def most_popular_new_interests(\n",
        "        user_interests : List[str],\n",
        "        max_results: int = 5) -> List[Tuple[str, int]]:\n",
        "    suggestions = [(interest, frequency)\n",
        "                    for interest, frequency in popular_interests.most_common()\n",
        "                    if interest not in user_interests]\n",
        "    return suggestions[:max_results]\n",
        "\n",
        "print(most_popular_new_interests(users_interests[1]))\n",
        "print(most_popular_new_interests(users_interests[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Python', 4), ('R', 4), ('Big Data', 3), ('Java', 3), ('statistics', 3)]\n",
            "[('Python', 4), ('R', 4), ('statistics', 3), ('regression', 3), ('probability', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlysjJvoIXQL",
        "outputId": "153717f9-daee-41ae-8805-12167c863d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Collaborative filtering to find new interests based on similarity to others who have similar things to you\n",
        "unique_interests = sorted({interest\n",
        "                           for user_interests in users_interests\n",
        "                           for interest in user_interests})\n",
        "assert unique_interests[:6] == [\n",
        "                                'Big Data',\n",
        "                                'C++',\n",
        "                                'Cassandra',\n",
        "                                'HBase',\n",
        "                                'Hadoop',\n",
        "                                'Haskell',\n",
        "]\n",
        "print(unique_interests)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Big Data', 'C++', 'Cassandra', 'HBase', 'Hadoop', 'Haskell', 'Java', 'Mahout', 'MapReduce', 'MongoDB', 'MySQL', 'NoSQL', 'Postgres', 'Python', 'R', 'Spark', 'Storm', 'artificial intelligence', 'databases', 'decision trees', 'deep learning', 'libsvm', 'machine learning', 'mathematics', 'neural networks', 'numpy', 'pandas', 'probability', 'programming languages', 'regression', 'scikit-learn', 'scipy', 'statistics', 'statsmodels', 'support vector machines', 'theory']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnQKxr-3K2Gq",
        "outputId": "0c8d38c5-c545-4188-edad-f65182ae98a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Next we produce an interest vector of 0s and 10s for each user\n",
        "def make_user_interest_vector(user_interests: List[str]) -> List[int]:\n",
        "  \"\"\"\n",
        "  Given a list of interests, produce a vector whose ith element is 1\n",
        "  if unique_interests[i] is in the list, 0 otherwise\n",
        "  \"\"\"\n",
        "  return [1 if interest in user_interests else 0\n",
        "          for interest in unique_interests]\n",
        "\n",
        "user_interest_vectors = [make_user_interest_vector(user_interests)\n",
        "                        for user_interests in users_interests]\n",
        "print(user_interest_vectors)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYSBpdML2Dn"
      },
      "source": [
        "# Because we have a small dataset, it's no problem to compute the pairwise similarities\n",
        "from Chapter_21 import cosine_similarity\n",
        "\n",
        "user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)\n",
        "                      for interest_vector_j in user_interest_vectors]\n",
        "                     for interest_vector_i in user_interest_vectors]\n",
        "\n",
        "assert 0.56 < user_similarities[0][9] < 0.58, \"several shared interests\"\n",
        "assert 0.18 < user_similarities[0][8] < 0.20, \"only one shared interest\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnq-blCkQQ-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}