{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+QN3+H+LUEWd322DYy5PJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamestheengineer/data-science-from-scratch-Python/blob/master/Chapter_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxsJpb6Al8qY"
      },
      "source": [
        "!git clone https://github.com/jamestheengineer/data-science-from-scratch-Python.git\n",
        "%cd data-science-from-scratch-Python/\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkXYd2_PWkcn"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "class User(NamedTuple):\n",
        "  id: int\n",
        "  name: str\n",
        "\n",
        "users = [User(0, \"Hero\"), User(1, \"Dunn\"), User(2, \"Sue\"), User(3, \"Chi\"),\n",
        "         User(4, \"Thor\"), User(5, \"Clive\"), User(6, \"Hicks\"),\n",
        "         User(7, \"Devin\"), User(8, \"Kate\"), User(9, \"Klein\")]\n",
        "\n",
        "friend_pairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
        "                (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "# type alias for keeping track ofr Friendships\n",
        "Friendships = Dict[int, List[int]]\n",
        "\n",
        "friendships: Friendships = {user.id: [] for user in users}\n",
        "\n",
        "for i, j in friend_pairs:\n",
        "  friendships[i].append(j)\n",
        "  friendships[j].append(i)\n",
        "\n",
        "assert friendships[4] == [3, 5]\n",
        "assert friendships[8] == [6,7,9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2SOEIZAXeLC"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "Path = List[int]\n",
        "\n",
        "def shortest_paths_from(from_user_id: int,\n",
        "                        friendships: Friendships) -> Dict[int, List[Path]]:\n",
        "    # A dictionary from user_id to *all* shortest paths to that user.\n",
        "    shortest_paths_to: Dict[int, List[Path]] = {from_user_id: [[]]}\n",
        "\n",
        "    # A queue of (previous user, next user) that we need to check.\n",
        "    # Starts out with all pairs(from_user, friend_of_from_user).\n",
        "    frontier = deque((from_user_id, friend_id)\n",
        "                      for friend_id in friendships[from_user_id])\n",
        "    \n",
        "    # Keep going until we empty the queue\n",
        "    while frontier:\n",
        "      # Remove the pair that's next in the queue.\n",
        "      prev_user_id, user_id = frontier.popleft()\n",
        "\n",
        "      # Because of the way we're adding to the queue,\n",
        "      # necessarily we already know some shortest paths to prev_user.\n",
        "      paths_to_prev_user = shortest_paths_to[prev_user_id]\n",
        "      new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n",
        "\n",
        "      # It's possible we already know a shortest path to user_id.\n",
        "      old_paths_to_user = shortest_paths_to.get(user_id, [])\n",
        "\n",
        "      # What's the shortest path to here that we've seen so far?\n",
        "      if old_paths_to_user:\n",
        "        min_path_length = len(old_paths_to_user[0])\n",
        "      else: \n",
        "        min_path_length = float('inf')\n",
        "\n",
        "      # Only keep paths that aren't too long and are actually new.\n",
        "      new_paths_to_user = [path\n",
        "                           for path in new_paths_to_user\n",
        "                           if len(path) <= min_path_length\n",
        "                           and path not in old_paths_to_user]\n",
        "      \n",
        "      shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n",
        "\n",
        "      # Add never seen neighbors to the frontier.\n",
        "      frontier.extend((user_id, friend_id)\n",
        "                      for friend_id in friendships[user_id]\n",
        "                      if friend_id not in shortest_paths_to)\n",
        "  \n",
        "    return shortest_paths_to"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzhU7rfogwbl"
      },
      "source": [
        "# For each from_user, for each to_user, a list of shortest paths\n",
        "shortest_paths = {user.id: shortest_paths_from(user.id, friendships)\n",
        "                    for user in users}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSNBQ2ATQG_g"
      },
      "source": [
        "betweenness_centrality = {user.id: 0.0 for user in users}\n",
        "\n",
        "for source in users:\n",
        "  for target_id, paths in shortest_paths[source.id].items():\n",
        "    if source.id < target_id: # don't double count\n",
        "      num_paths = len(paths)\n",
        "      contrib = 1 / num_paths\n",
        "      for path in paths:\n",
        "        for between_id in path:\n",
        "          if between_id not in [source.id, target_id]:\n",
        "            betweenness_centrality[between_id] += contrib\n",
        "\n",
        "print(betweenness_centrality)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYRF8G1TQ7-j"
      },
      "source": [
        "# Closeness centrality\n",
        "def farness(user_id: int) -> float:\n",
        "  \"\"\"The sum of the lengths of the shortest paths to each other user\"\"\"\n",
        "  return sum(len(paths[0])\n",
        "              for paths in shortest_paths[user_id].values())\n",
        "  \n",
        "closeness_centrality = {user.id: 1 / farness(user.id) for user in users}\n",
        "print(closeness_centrality)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXBsWyDKUmzM"
      },
      "source": [
        "# Computing shortest paths is kinda a pain, thus not used much on large networks. Usually, we use eigenvector centrality\n",
        "from Chapter_04 import Matrix, make_matrix, shape\n",
        "\n",
        "def matrix_times_matrix(m1: Matrix, m2: Matrix) -> Matrix:\n",
        "  nr1, nc1 = shape(m1)\n",
        "  nr2, nc2 = shape(m2)\n",
        "\n",
        "  assert nc1 == nr2, \"must have (# of columns in m1) == (# of rows in m2)\"\n",
        "\n",
        "  def entry_fn(i: int, j: int) -> float:\n",
        "    \"\"\"dot product of i-th row of m1 with j-th column of m2\"\"\"\n",
        "    return sum(m1[i][k] * m2[k][j] for k in range(nc1))\n",
        "\n",
        "  return make_matrix(nr1, nc2, entry_fn)\n",
        "\n",
        "from Chapter_04 import Vector, dot\n",
        "\n",
        "def matrix_times_vector(m: Matrix, v: Vector) -> Vector:\n",
        "  nr, nc = shape(m)\n",
        "  n = len(v)\n",
        "  assert nc == n, \"must hae (# cols in m) == (# elements in v)\"\n",
        "\n",
        "  return [dot(row, v) for row in m] # output has length nr\n",
        "\n",
        "from typing import Tuple\n",
        "import random\n",
        "from Chapter_04 import magnitude, distance\n",
        "\n",
        "def find_eigenvector(m: Matrix,\n",
        "                     tolerance: float = 0.00001) -> Tuple[Vector, float]:\n",
        "    guess = [random.random() for _ in m]\n",
        "\n",
        "    while True:\n",
        "      result = matrix_times_vector(m, guess) # transform guess\n",
        "      norm = magnitude(result) # compute norm\n",
        "      next_guess = [x / norm for x in result] # rescale\n",
        "\n",
        "      if distance(guess, next_guess) < tolerance:\n",
        "        # convergence so return (eigenvector, eigenvalue)\n",
        "        return next_guess, norm\n",
        "        \n",
        "      guess = next_guess\n",
        "\n",
        "def entry_fn(i: int, j: int):\n",
        "  return 1 if (i,j) in friend_pairs or (j,i) in friend_pairs else 0\n",
        "\n",
        "n = len(users)\n",
        "adjacency_matrix = make_matrix(n,n, entry_fn)\n",
        "\n",
        "[x,y] = find_eigenvector(adjacency_matrix)\n",
        "print(x,y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk085k0_lDRa"
      },
      "source": [
        "# Directed graphs and pagerank\n",
        "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n",
        "                (2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n",
        "                (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "endorsement_counts = Counter(target for source, target in endorsements)\n",
        "\n",
        "import tqdm\n",
        "\n",
        "def page_rank(users: List[User],\n",
        "              endorsements: List[Tuple[int, int]],\n",
        "              damping: float = 0.85,\n",
        "              num_iters: int = 100) -> Dict[int, float]:\n",
        "    # Compute how many people each person endorses\n",
        "    outgoing_counts = Counter(target for source, target in endorsements)\n",
        "    print(outgoing_counts)\n",
        "    # Initially distribute PageRank evenly\n",
        "    num_users = len(users)\n",
        "    pr = {user.id : 1 / num_users for user in users}\n",
        "\n",
        "    # Small fraction of PageRank that each node gets each iteration\n",
        "    base_pr = (1 - damping) / num_users\n",
        "\n",
        "    for iter in tqdm.trange(num_iters):\n",
        "      next_pr = {user.id : base_pr for user in users} # start with base_pr\n",
        "\n",
        "      for source, target in endorsements:\n",
        "        # Add damped fraction of source pr to target\n",
        "        next_pr[target] += damping * pr[source] / outgoing_counts[source]\n",
        "      \n",
        "      pr = next_pr\n",
        "    \n",
        "    return pr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bf733HthnHO",
        "outputId": "1286ce26-2b54-45ab-ffa6-f656ad08e360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pr = page_rank(users, endorsements)\n",
        "print(pr)\n",
        "assert pr[4] > max(page_rank for user_id, page_rank in pr.items() if user_id != 4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 63888.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 2, 0: 2, 2: 2, 3: 2, 4: 2, 6: 1, 5: 1, 8: 1, 7: 1, 9: 1})\n",
            "{0: 0.1, 1: 0.1, 2: 0.1, 3: 0.1, 4: 0.14250000000000002, 5: 0.1, 6: 0.1, 7: 0.1, 8: 0.1, 9: 0.1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfom-XNMidx_",
        "outputId": "c4a96e02-6061-4032-884d-f6bdc696620c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Thor (user_id 4) has higher page rank than anyone else\n",
        "assert pr[4] > max(page_rank\n",
        "                   for user_id, page_rank in pr.items()\n",
        "                   if user_id != 4)\n",
        "print(pr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.1, 1: 0.1, 2: 0.1, 3: 0.1, 4: 0.14250000000000002, 5: 0.1, 6: 0.1, 7: 0.1, 8: 0.1, 9: 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VOfWGNAkkmj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}